<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Lin Zhao</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Lin Zhao
                </p>
                <p>I am an incoming PHD student at <a href="https://ece.northeastern.edu/">Department of Electrical & Computer Engineering, Northeastern University</a>. My research interests include deep learning algorithm, multi-modal AI and generative model. I got my M.S. and B.S. degrees from <a href="https://www.nankai.edu.cn/">Nankai University</a>, in 2023 and 2020, advised by <a href="https://bigdata.nankai.edu.cn/yangzl">Prof. Zhenglu Yang</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:lin-zhao@mail.nankai.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/cv.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?view_op=list_works&hl=zh-CN&user=Rw9iX_oAAAAJ">Scholar</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/LinZhao.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/LinZhao.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/FlashEval.png" alt="clean-usnob" width="320" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="">
                  <span class="papertitle">FlashEval: Towards Fast and Accurate Evaluation of Text-to-image Diffusion Generative Models</span>
                </a>
                <br>
                <strong>Lin Zhao*</strong>, <a href="">Tianchen Zhao*</a>, <a href="">Zinan Lin</a>, <a href="">Xuefei Ning</a>, <a href="">Guohao Dai</a>, <a href="">Huazhong Yang</a>, <a href="">Yu Wang</a>
                <br>
                <em>Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
                <p>We propose FlashEval, which can identify a representative subset to speed up the evaluation of text-to-image Diffusion models (10x).</p>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/THInImg.png" alt="clean-usnob" width="320" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Zhao_THInImg_Cross-Modal_Steganography_for_Presenting_Talking_Heads_in_Images_WACV_2024_paper.pdf">
                  <span class="papertitle">THInImg: Cross-modal Steganography for Presenting Talking Heads in Images</span>
                </a>
                <br>
                <strong>Lin Zhao</strong>, <a href="">Hongxuan Li</a>, <a href="">Xuefei Ning</a>, <a href="">Xinru Jiang</a>
                <br>
                <em>Winter Conference on Applications of Computer Vision (<strong>WACV</strong>)</em>, 2024
                <p>We propose THInImg, which can present up to 80 seconds of high quality talking-head video (including audio) in an identity image with 160Ã—160 resolution.</p>
              </td>
            </tr>


            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/Enhancement.png" alt="clean-usnob" width="320" height="160">
              </td>
              <td width="75%" valign="middle">
                <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Deep_Symmetric_Network_for_Underexposed_Image_Enhancement_With_Recurrent_Attentional_ICCV_2021_paper.pdf">
                  <span class="papertitle">Deep Symmetric Network for Underexposed Image Enhancement with Recurrent Attentional Learning</span>
                </a>
                <br>
                <strong>Lin Zhao*</strong>, <a href="">Shaoping Lu*</a>, <a href="">Tao Chen</a>, <a href="">Zhenglu Yang</a>, <a href="">Ariel Shamir</a>
                <br>
                <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021
                <p>We propose an invertible framework to solve both underexposed image enhancement and low-light image enhancement problems in a unified structure. <a href="https://www.shaopinglu.net/proj-iccv21/ImageEnhancement.html">[project]</a></p>
              </td>
            </tr>

          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Work Experiences</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/tsinghua.png" width="120" height="120"></td>
              <td width="75%" valign="center">
                <p><strong>Research Assistant, NICS-EFC group, Tsinghua University</strong></p> 
                <em>Jul 2023 - Dec 2023, Beijing, China</em>
                <p>Worked on Machine Learning Algorithm</p> 
                <p>Professor: <a href="https://nicsefc.ee.tsinghua.edu.cn/people/YuWang">Prof. Yu Wang</a> and <a href="https://www.ningxuefei.cc/">Prof. Xuefei Ning</a></p> 
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/msra.png" width="200" height="100"></td>
              <td width="75%" valign="center">
                <p><strong>Research Intern, Media Computing Group, Microsoft Research Asia</strong></p> 
                <em>Jul 2022 - Dec 2022, Beijing, China</em>
                <p>Worked on Talking-head Generation and Video Compression</p> 
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/sensetime.png" width="200" height="80"></td>
              <td width="75%" valign="center">
                <p><strong>Research Intern, Multimodal Group, Sensetime</strong></p> 
                <em>Mar 2022 - May 2022, Beijing, China</em>
                <p>Worked on Video Editing</p> 
              </td>
            </tr>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <h2>Selected Honors & Awards</h2>
                  <p>Gongneng Scholarship. 2021</p> 
                  <p>Graduate Student Scholarship. 2020</p>
                  <p>Comprehensive First-class Scholarship (Top 5%). 2018, 2019</p>
                  <p>Honorable Mention, Mathematical Contest in Modeling. 2019</p>
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>



            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
              <tr>
                <td>
                  <h2>Misc</h2> 
                  <p>I was born and raised in <a href="https://en.wikipedia.org/wiki/Harbin">Harbin, China</a>.</p> 
                  <p>I enjoy running, cooking and singing.</p>
                  <p>I especially love little monkeys; they are just too adorable!</p>
                </td>
              </tr>
            </tbody></table>
            <table width="100%" align="center" border="0" cellpadding="20"><tbody>
              
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
